import anndata as ad
from scdataloader import Preprocessor
import sys
from huggingface_hub import hf_hub_download
from scprint.tasks import Embedder
from scprint import scPrint

## VIASH START
# Note: this section is auto-generated by viash at runtime. To edit it, make changes
# in config.vsh.yaml and then run `viash config inject config.vsh.yaml`.
par = {
  'input': 'resources_test/.../input.h5ad',
  'output': 'output.h5ad'
}
meta = {
  'name': 'scprint'
}
## VIASH END

sys.path.append(meta["resources_dir"])
from read_anndata_partial import read_anndata

print(">>> Reading input data...", flush=True)
input = read_anndata(par["input"], X="layers/counts", obs="obs", var="var", uns="uns")

print("\n>>> Setting ontology term IDs...", flush=True)
# For now, set all ontology term IDs to 'unknown' but these could be used for
# cellxgene datasets that have this information
print("NOTE: All ontology term IDs except organism are set to 'unknown'", flush=True)
if input.uns["dataset_organism"] == "homo_sapiens":
    input.obs["organism_ontology_term_id"] = "NCBITaxon:9606"
elif input.uns["dataset_organism"] == "mus_musculus":
    input.obs["organism_ontology_term_id"] = "NCBITaxon:10090"
else:
    raise ValueError(f"scPRINT requires human or mouse data, not '{input.uns['dataset_organism']}'")
input.obs["self_reported_ethnicity_ontology_term_id"] = "unknown"
input.obs["disease_ontology_term_id"] = "unknown"
input.obs["cell_type_ontology_term_id"] = "unknown"
input.obs["development_stage_ontology_term_id"] = "unknown"
input.obs["tissue_ontology_term_id"] = "unknown"
input.obs["assay_ontology_term_id"] = "unknown"
input.obs["sex_ontology_term_id"] = "unknown"

print('\n>>> Preprocessing data...', flush=True)
preprocessor = Preprocessor(
    # Lower this threshold for test datasets
    min_valid_genes_id = 1000 if input.n_vars < 2000 else 10000,
    # Turn off cell filtering to return results for all cells
    filter_cell_by_counts = False,
    min_nnz_genes = False,
    do_postp=False
)
processed = preprocessor(input)

print('\n>>> Downloading model...', flush=True)
model = "small" # TODO: Add other models
model_checkpoint_file = hf_hub_download(
    repo_id="jkobject/scPRINT",
    filename=f"{model}.ckpt"
)
print(f"Model checkpoint file: '{model_checkpoint_file}'", flush=True)


model = scPrint.load_from_checkpoint(
    model_checkpoint_file,
    transformer = "normal", # TODO: Don't use this for GPUs with flashattention
    precpt_gene_emb = None
)

print('\n>>> Embedding data...', flush=True)
import torch
embedder = Embedder(
    how="random expr",
    max_len=4000,
    add_zero_genes=0,
    num_workers=8, # TODO: Detect and set number of workers
    doclass = False,
    doplot = False,
    devices = None,
    precision = "32", # TODO: Use float16 for GPUs
    dtype = torch.float32,
)
print(embedder.precision)
print(embedder.dtype)

embedded, metrics = embedder(model, processed, cache=False)
print(embedded)
print(metrics)

print('Train model', flush=True)
# ... train model ...

print('Generate predictions', flush=True)
# ... generate predictions ...

print("Write output AnnData to file", flush=True)
output = ad.AnnData(

)
output.write_h5ad(par['output'], compression='gzip')
