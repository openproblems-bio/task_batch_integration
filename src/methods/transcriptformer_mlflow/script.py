import anndata as ad
import sys
import mlflow.pyfunc
import tempfile
import os
import pandas as pd
import zipfile
import tarfile

## VIASH START
# Note: this section is auto-generated by viash at runtime. To edit it, make changes
# in config.vsh.yaml and then run `viash config inject config.vsh.yaml`.
par = {
    "input": "resources_test/.../input.h5ad",
    "output": "output.h5ad",
    "model": "resources_test/.../model",
}
meta = {"name": "transcriptformer_mlflow"}
## VIASH END

sys.path.append(meta["resources_dir"])
from read_anndata_partial import read_anndata
from exit_codes import exit_non_applicable

print(f"====== TranscriptFormer (MLflow model) ======", flush=True)

print("\n>>> Reading input files...", flush=True)
print(f"Input H5AD file: '{par['input']}'", flush=True)
adata = read_anndata(par["input"], X="layers/counts", obs="obs", var="var", uns="uns")

if adata.uns["dataset_organism"] != "homo_sapiens":
    exit_non_applicable(
        f"Transcriptformer can only be used with human data "
        f"(dataset_organism == \"{adata.uns['dataset_organism']}\")"
    )

print(adata, flush=True)

if os.path.isdir(par["model"]):
    print("\n>>> Using model directory...", flush=True)
    model_temp = None
    model_dir = par["model"]
else:
    model_temp = tempfile.TemporaryDirectory()
    model_dir = model_temp.name

    if zipfile.is_zipfile(par["model"]):
        print("\n>>> Extracting model from .zip...", flush=True)
        print(f".zip path: '{par['model']}'", flush=True)
        with zipfile.ZipFile(par["model"], "r") as zip_file:
            zip_file.extractall(model_dir)
    elif tarfile.is_tarfile(par["model"]) and par["model"].endswith(
        ".tar.gz"
    ):
        print("\n>>> Extracting model from .tar.gz...", flush=True)
        print(f".tar.gz path: '{par['model']}'", flush=True)
        with tarfile.open(par["model"], "r:gz") as tar_file:
            tar_file.extractall(model_dir)
            model_dir = os.path.join(model_dir, os.listdir(model_dir)[0])
    else:
        raise ValueError(
            "The 'model' argument should be a directory a .zip file or a .tar.gz file"
        )

print("\n>>> Loading model...", flush=True)
model = mlflow.pyfunc.load_model(model_dir)
print(model, flush=True)

print("\n>>> Writing temporary input H5AD file...", flush=True)
input_adata = ad.AnnData(X = adata.X.copy(), var = adata.var.filter(items=["feature_id"]).rename(columns = {"feature_id": "ensembl_id"}))
input_adata.obs["assay"] = "unknown" # Avoid error if assay is missing
print(input_adata, flush=True)
h5ad_file = tempfile.NamedTemporaryFile(suffix=".h5ad", delete=False)
print(f"Temporary H5AD file: '{h5ad_file.name}'", flush=True)
input_adata.write(h5ad_file.name)
del input_adata

print("\n>>> Running model...", flush=True)
input_df = pd.DataFrame({"input_uri": [h5ad_file.name]})
embedding = model.predict(input_df)

print("\n>>> Storing output...", flush=True)
output = ad.AnnData(
    obs=adata.obs[[]],
    var=adata.var[[]],
    obsm={
        "X_emb": embedding,
    },
    uns={
        "dataset_id": adata.uns["dataset_id"],
        "normalization_id": adata.uns["normalization_id"],
        "method_id": meta["name"],
    },
)
print(output)

print("\n>>> Writing output to file...", flush=True)
print(f"Output H5AD file: '{par['output']}'", flush=True)
output.write_h5ad(par["output"], compression="gzip")

print("\n>>> Cleaning up temporary files...", flush=True)
if model_temp is not None:
    model_temp.cleanup()
h5ad_file.close()
os.unlink(h5ad_file.name)

print("\n>>> Done!", flush=True)
